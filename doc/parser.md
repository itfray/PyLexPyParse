# Parser

The parser is the part of the translator that is responsible for identifying and checking the syntax of the input language. The parser receives a string of tokens from the lexer and checks if this string of tokens can be generated by the grammar of the input language. Another function of the parser is to generate messages about all detected errors, and quite clear and complete, and in addition, the parser must be able to handle common, common errors and continue working with the rest of the program. In the case of a correct program, the parser builds a parse tree and passes it to the next part of the compiler for further processing.

The parser has two main tasks: to check the correctness of the constructions of the program, which is presented in the form of already selected words of the input language, and to transform it into a form convenient for further semantic (semantic) processing and code generation. One way to do this is with a parse tree.

The basis for constructing the recognizers of context-free languages are magazine memory machine - PDA - one-way non-deterministic recognizers with linearly bounded push-down memory.

The PDA, in contrast to the usual finite automaton, has a stack (store) into which special “store” symbols can be placed (usually these are terminal and non-terminal symbols of the grammar of the language). The transition of the PDA from one state to another depends not only on the input symbol, but also on one or more top symbols of the stack. Thus, the configuration of an automaton is determined by three parameters: the state of the automaton, the current symbol of the input string (the position of the pointer in the string), and the contents of the stack.

The parser of any translator can be implemented as a deterministic push-down automaton.

In this project, bottom-up parsing algorithms were used to implement the parser.

Consider, for example, a grammar with the following rules:

    A -> A + B | A - B | B
    B -> B * C | B / C | C
    C -> ( A ) | ID

Let's consider the actions of the analyzer that uses the shift-roll up algorithm for parsing the string:

    ID / ID

An analyzer using this algorithm can perform four actions:
1. Shift. Transferring the next input character to the top of the stack;
1. Convolution. The right side of the string to be folded must be at the top of the stack. The left end of the string on the stack is determined and a decision is made about which non-terminal will replace the string.
1. Acceptance. Announcement of the successful completion of parsing;
1. Error. Syntax error detection and error recovery.

|Stack|Input|Action|
|:----|:----|:----|
|⊥|ID / ID⊥|Shift|
|⊥ID|/ ID⊥|Roll up (C→ID)|
|⊥ C|/ ID⊥|Roll up (B→C)|
|⊥B|/ ID⊥|Shift|
|⊥ B / |ID⊥|Shift|
|⊥ B / ID|⊥|Roll up (C→ID)|
|⊥ B / C|⊥|Roll up (B→B / C)|
|⊥ B|⊥|Roll up (A→B)|
|⊥ A|⊥|Accept|

To create a parser in this work, we used the implementation of the "shift-roll up" algorithm based on the use of LR(1) - grammar and its modification LALR(1) - grammar.

The `Sparser` class implements the `ISParser` interface. Let's describe some basic methods for working with this class:

- `rules(): list(Rule, …)` – get a list of language grammar rules;
- `parse_rules(str)` – convert the text specification of the language grammar into a list of grammar rules for the parser. A grammar specification of a language is a textual description of grammatical rules in a description form that corresponds to the Backus-Naur form;
- `term_segreg()` – get or assign a tuple of characters that are a segregation of terminal characters (tokens) in the parser specification text;
- `tokens()` – assign or get tokens, which are terminal symbols of the language grammar;
- `goal_nterm(): str` - get or assign the target symbol of the grammar of the language;
- `end_term(): str` - get or assign the end symbol of the language grammar;
- `empty_term()` - get or assign an empty string symbol for the grammar of the language;
- `parse(): Node` - Parses the incoming stream of tokens and builds a parse tree, where the nodes of the tree are objects of class `Node`;
- `lexer(): ILexer` - Lexer access property. Provides the ability to set or get a lexical analyzer for the parser;
- `create_sparse_tab()` – a method for generating a canonical table of LALR(1)-analysis based on previously obtained rules, term_segreg, tokens, goal_nterm, end_term and empty_term. Here an extended grammar is created in relation to the given one. LR(1)-states are constructed for the LR(1)-automaton. The final LR(1) automaton is transformed into an LALR(1) automaton and a canonical parse table is generated on its basis;
- `write_stab_to_file(str)` – write the canonical LALR(1) analysis table to a binary file;
- `read_stab_from_file(str)` – read the canonical table of LALR(1) analysis from a binary file.

Detailed description method `parse(): Node`:

1. A list of objects of the `Node` class is used as a character buffer. This means that with each shift, the parser creates a new `Node` object and places the `Token` received from the lexical analyzer in its value field;
1. When folding, the analyzer creates a new node `Node` and extracts a certain number of nodes from the node buffer according to the rule by which the folding is performed. The parser places the extracted nodes as child nodes for the newly created `Node`, that is, it adds these objects to the childs list of the created node. For each of the child nodes, the created node is set to the parent field, that is, it becomes their parent;
1. In the case of an accept, the parser extracts the last node from the node buffer and returns it from the method as the root of the parse parse tree;
1. In case of errors during parsing, this method throws exceptions that must be handled in the procedure that called this method.